{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "i = 0\n",
    "for elem in data:\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    X.append(tf.resize(elem[0], output_shape=(40,40)))\n",
    "    Y.append(elem[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('X', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('Y', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load(\"X.npy\")\n",
    "Y = np.load(\"Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.resize((166708,40,40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.unique(Y)\n",
    "labels = labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    Y[i] = labels.index(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.0005, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_84 (Convolution2D) (None, 38, 38, 80)    800         convolution2d_input_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 38, 38, 80)    0           convolution2d_84[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_73 (MaxPooling2D)   (None, 19, 19, 80)    0           activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_85 (Convolution2D) (None, 17, 17, 160)   115360      maxpooling2d_73[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 17, 17, 160)   0           convolution2d_85[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_74 (MaxPooling2D)   (None, 16, 16, 160)   0           activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 16, 16, 160)   320         maxpooling2d_74[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_86 (Convolution2D) (None, 14, 14, 240)   345840      batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 14, 14, 240)   0           convolution2d_86[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_75 (MaxPooling2D)   (None, 7, 7, 240)     0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_87 (Convolution2D) (None, 5, 5, 320)     691520      maxpooling2d_75[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 5, 5, 320)     0           convolution2d_87[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_76 (MaxPooling2D)   (None, 2, 2, 320)     0           activation_100[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 2, 2, 320)     640         maxpooling2d_76[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 1280)          0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 50)            64050       flatten_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 50)            0           dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 50)            100         activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 500)           25500       batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 500)           0           dense_18[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 1244130\n",
      "____________________________________________________________________________________________________\n",
      "Train on 116695 samples, validate on 50013 samples\n",
      "Epoch 1/10\n",
      "166s - loss: 2.9526 - acc: 0.5068 - val_loss: 0.9755 - val_acc: 0.7559\n",
      "Epoch 2/10\n",
      "163s - loss: 0.5272 - acc: 0.8920 - val_loss: 1.0151 - val_acc: 0.7371\n",
      "Epoch 3/10\n",
      "164s - loss: 0.2749 - acc: 0.9367 - val_loss: 0.7296 - val_acc: 0.8067\n",
      "Epoch 4/10\n",
      "164s - loss: 0.1738 - acc: 0.9584 - val_loss: 0.4844 - val_acc: 0.8678\n",
      "Epoch 5/10\n",
      "164s - loss: 0.1197 - acc: 0.9707 - val_loss: 0.9287 - val_acc: 0.7649\n",
      "Epoch 6/10\n",
      "164s - loss: 0.0860 - acc: 0.9789 - val_loss: 0.5428 - val_acc: 0.8522\n",
      "Epoch 7/10\n",
      "164s - loss: 0.0665 - acc: 0.9832 - val_loss: 1.4959 - val_acc: 0.6927\n",
      "Epoch 8/10\n",
      "164s - loss: 0.0564 - acc: 0.9852 - val_loss: 0.5643 - val_acc: 0.8645\n",
      "Epoch 9/10\n",
      "164s - loss: 0.0479 - acc: 0.9872 - val_loss: 0.6321 - val_acc: 0.8521\n",
      "Epoch 10/10\n",
      "164s - loss: 0.0449 - acc: 0.9871 - val_loss: 0.6018 - val_acc: 0.8511\n",
      "Test score: 0.601824136281\n",
      "Test accuracy: 0.851098714337\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 500\n",
    "nb_epoch = 10\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "input_shape = (40,40,1)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Convolution2D(80, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Convolution2D(160, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=(1,1)))\n",
    "          \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Convolution2D(240, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(320, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=2, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 166624 samples, validate on 84 samples\n",
      "Epoch 1/5\n",
      "206s - loss: 0.0139 - acc: 0.9960 - val_loss: 0.2284 - val_acc: 0.9643\n",
      "Epoch 2/5\n",
      "206s - loss: 0.0128 - acc: 0.9963 - val_loss: 0.3614 - val_acc: 0.9405\n",
      "Epoch 3/5\n",
      "206s - loss: 0.0103 - acc: 0.9972 - val_loss: 0.6435 - val_acc: 0.8571\n",
      "Epoch 4/5\n",
      "206s - loss: 0.0131 - acc: 0.9962 - val_loss: 0.3211 - val_acc: 0.9286\n",
      "Epoch 5/5\n",
      "206s - loss: 0.0112 - acc: 0.9968 - val_loss: 0.1837 - val_acc: 0.9524\n",
      "Test score: 0.183740199322\n",
      "Test accuracy: 0.952380949543\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=5,\n",
    "          verbose=2, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"4 conv with maxpool and batchnorm V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(\"./Models Architecture/mnist_cnn_architecture_first_sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n"
     ]
    }
   ],
   "source": [
    "import skimage.transform\n",
    "\n",
    "test_set = []\n",
    "i = 0\n",
    "for elem in test:\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    test_set.append(skimage.transform.resize(elem, output_shape=(40,40)))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = np.array(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41428, 40, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set.resize((41428,40,40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = model.predict_classes(test_set, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(ans)):\n",
    "    ans[i] = labels[ans[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = pd.DataFrame(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = [i+1 for i in range(len(test_set))]\n",
    "\n",
    "temp = pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.concat([temp, ans], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.columns = ['Id', 'Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = result.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt(\"fourth_sub.csv\", result, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
